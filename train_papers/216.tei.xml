<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/lopez/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5-SNAPSHOT" ident="GROBID" when="2019-03-19T09:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reducing the ATHENA WFI background</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuehao</forename><surname>Ding</surname></persName>
						</author>
						<title level="a" type="main">Reducing the ATHENA WFI background</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>The Wide Field Imager (WFI) on Athena X-ray observatory is a detector system which will include on-board processing algorithms designed to reduce the particle background <ref type="bibr" target="#b0">[1]</ref>. In this project, I make use of the unsupervised learning algorithm and deep learning method to identify and eliminate the background. The algorithms in this project are tested on images generated from GEANT4 and SIXTE simulated datasets, which shows that machine learning methods are effective in distinguishing between photon-induced and proton-induced patterns on the detector.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The main component of the instrumental background is generated by high energy protons (with E &gt; 100M eV ) that produce secondaries along their way by depositing some of their energy. The secondaries of the unfocused component detected by the WFI are hard to distinguish from X-ray events from celestial sources.</p><p>In this project, my main goal is to reduce the WFI background by using machine learning methods. The input to my algorithm is a 500 by 500 grayscale image, where the value of each pixel represents its energy. I then use DBSCAN (an unsupervised algorithm) to cluster the nonzero pixels and use neural network to identify if each cluster includes a photon. The final output is a processed 500 by 500 image where the background has been eliminated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>There are some existing works to understand, model, and reduce the WFI background with classical algorithms without using deep learning method. One of the approaches is to reject hits which are next to a pixel whose deposited energy is more than 15 keV <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref>. The reasoning behind this threshold is that energy deposits above 15 keV are much more likely to originate from particles than from photons. And secondary particles produced by such a high energetic primary tend to be close to the primary which produced them. Another approach is to study spacial correlations between particle events and photon events, which is helpful to improve the rejection of particle background events <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5]</ref>. What's more, in Ref. <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6]</ref>, each event is assigned a grade based on the 3 by 3 pattern of pixels above a threshold using ASCA grading scheme. Events with grades ≤ 12 are flagged to be photon events and events with grades &gt; 12 are considered as particle events.</p><p>In summary, these existing works all tried to find features manually to distinguish between particles and X-ray photons. In contrast, my project aims to discover features using deep learning neural network, which is the main difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset and Features</head><p>The data I analyze are from GEANT4 <ref type="bibr" target="#b6">[7]</ref> simulated WFI particle background data and SIXTE <ref type="bibr" target="#b7">[8]</ref> simulated X-ray data. GEANT4 simulates particles through the telescope and records how they interact with the detector. SIXTE simulates the X-ray detected and the interaction with the detector.</p><p>An input sample to DBSCAN records the energy levels of the pixels on the detector in one frame, which is a 500 by 500 grayscale image. <ref type="figure" target="#fig_0">Fig. 1</ref> shows some typical patterns of photons and particles. The color of each pixel represents its energy level. In the real case, there are many such patterns on the detector in each frame and it is also possible that multiple events overlap each other. For example, the left panel of <ref type="figure" target="#fig_3">Fig. 4</ref> is an input sample to DBSCAN. For the neural network, each input sample is a single-cluster grayscale image, which is a 50 by 50 matrix. I create 10000 train samples and 6000 validation samples by combining events from GEANT4 and SIXTE databases randomly. Each created sample is checked by DBSCAN whether it contains only one cluster and the sample will be discarded if not. Each sample may contain 0 − 1 photon and 0 − 2 particles, considering the probability that more events form a cluster in one frame is neglectable in the real case. A sample will be labeled as 1 if it contains a photon, and 0 otherwise. <ref type="figure" target="#fig_1">Fig. 2</ref> shows some examples.</p><p>Before sending the single-cluster figures into the neural network, I map every pixel value through the Heaviside step function. In other words, I assign a constant value to every non-zero pixel. This preprocessing is very useful because it turns out that the prediction accuracy becomes more than 99% in this case, while the prediction accuracy will be only about 70% if the neural network runs on the single-cluster figures directly. The intuitive reason for this is that the energy of a photon is most probably much weaker than that of a particle, which results in that the neural network does not "pay much attention" to photon pixels.</p><p>The feature in the algorithm is just the original input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods:</head><p>In this project, I use DBSCAN, an unsupervised learning algorithm, to cluster the activated pixels, and use deep learning algorithm to identify whether each cluster contains photons or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">DBSCAN</head><p>The ultimate goal of this project is to identify whether each activated pixel belongs to a photon or a particle. But it is not practical to run a neural network on the whole detector image. The goal of this section is to cluster the activated pixels based on their connectivity, where each cluster will be processed by the neural network in the next section.</p><p>After comparing several unsupervised learning algorithms, I found that DBSCAN (Densitybased spatial clustering of applications with noise) algorithm <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref> is best suited for our problem. The basic idea of DBSCAN is that every point in a cluster should have several nearby neighbors that also belong to this cluster. DBSCAN has two parameters: , which is the radius for each point to search for its nearby neighbors, and minP ts, which is the minimum number of points within the radius for a point to be considered as a core point. The procedure of DBSCAN is as follows:</p><p>1. Classify each data point: Core point: A point that has at least minP ts neighbor points within its radius. Border point: A point within the radius of a core point but has less than minP ts other points within its own radius. Noise point: A point that is neither a core point or a border point. <ref type="figure" target="#fig_2">Fig. 3</ref> is an example. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>If one data point is within the radius of a core point, these two points are considered directly density-reachable. Larger clusters are formed when directly density-reachable points are chained together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Deep Learning</head><p>After the preprocessing mentioned above, the input (50 by 50 matrix) will be processed by the neural network <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>The first layer of this neural network transforms the images from a matrix (of 50 by 50 pixels), to a 1d-array of 50 * 50 = 2500 elements.</p><p>After the inputs are flattened, the network consists of a sequence of two fully-connected neural layers. The first fully-connected layer is a 256-nodes Relu layer. The second (and last) layer is a single-node sigmoid layer which returns the probability that the label of this figure is 1. This process can be expressed as equations:</p><formula xml:id="formula_0">a [1] = max{0, W [1]T x f lat } (1) p(y = 1) = 1 1 + exp(−W [2]T a [1] )<label>(2)</label></formula><p>The final prediction accuracy of the network on the validation set is 99.1%.</p><p>What's more, I have also tried CNN network. But the accuracy is only about 50%, which is much poorer than the fully-connected network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment:</head><p>In my experiment, for DBSCAN, I set = 3 and minP ts = 3, in which case the algorithm clusters activated pixels pretty well. I created 1000 500 by 500 detector images from GEANT4 and SIXTE databases randomly for test, each of which includes 50 particle events and 50 X-ray events (left panel of <ref type="figure" target="#fig_3">Fig. 4</ref> as an example). After processing the images using DBSCAN and the deep learning neural network, I reject the clusters whose predicted labels are smaller than 0.5. The clusters whose labels are greater than 0.5 are kept in order to ensure the X-ray information not lost.</p><p>In order to evaluate the error of my algorithm, I compare each processed image with the corresponding perfect image (generated together with the test set, but no particle included). The performance metric in this project is defined as:</p><formula xml:id="formula_1">metric = N output only + N perf ect only N perf ect ,<label>(3)</label></formula><p>where N output only , N perf ect only represent the number of non-zero pixels only in the processed image and the perfect image, respectively, N perf ect represents the number of non-zero pixels in the perfect image. The simulation turns out that the average of the metric over 1000 test samples is equal to 97.2%.</p><p>For the purpose of giving an example, <ref type="figure" target="#fig_3">Fig. 4</ref> shows a image before processing (the left panel) and after processing (the right panel). Compare these two images carefully, one can see that all particle tracks far away from X-ray photons are eliminated perfectly, and all photons away from particles are kept. However, if a photon overlaps with a particle, it will be possible for the algorithm to make a mistake. That is, they may be discarded together rather than kept. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future work:</head><p>In summary, I use DBSCAN unsupervised learning algorithm to divide the raw image into clusters for the convenience of later processing. Then I use deep learning neural network to predict whether a cluster includes useful information and reject useless ones. The experiment shows that my algorithm performs very well on simulated data.</p><p>One natural future work is to run my algorithm on real data collected by other satellites. What's more, in my project, I do not modify clusters containing both particles and photons, for the sake of not losing X-ray information. Therefore, one another possible future work is to deal with those clusters very carefully to eliminate particle noises while keeping photons.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The upper three figures are examples of photons. The lower three figures are examples of particles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Three samples of the train set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>A is a core point. B and C are border points. N is a noise point.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>The left panel shows the image before processing, the right panel shows the image after processing.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>I would like to thank Prof. Steven Allen's lab for the use of the GEANT4 and SIXTE databases as well as Dr. Dan Wilkins for immensely useful discussions and advice.</p><p>Code https://github.com/Max-Snow/Reducing-Athena-particle-background</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The wide field imager instrument for Athena</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norbert</forename><surname>Meidinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">9144</biblScope>
		</imprint>
	</monogr>
	<note>Ultraviolet to Gamma Ray.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The ATHENA WFI science products module</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">N</forename><surname>Burrows</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">10699</biblScope>
		</imprint>
	</monogr>
	<note>Ultraviolet to Gamma Ray.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Evaluation of the Athena/WFI instrumental background</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Von Kienlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andreas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ultraviolet to Gamma Ray</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">10699</biblScope>
		</imprint>
	</monogr>
	<note>International Society for Optics and Photonics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Predicting the particle-induced background for future x-ray astronomy missions: the importance of experimental validation for GEANT4 simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">10709</biblScope>
		</imprint>
	</monogr>
	<note>High Energy, Optical, and Infrared Detectors for</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Characterizing particle background of ATHENA WFI for the science products module: swift XRT full frame and XMM-PN small window mode observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esra</forename><surname>Bulbul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Space Telescopes and Instrumentation</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">10699</biblScope>
		</imprint>
	</monogr>
	<note>International Society for Optics and Photonics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reducing the ATHENA WFI background with the science products module: lessons from Chandra ACIS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><forename type="middle">E</forename><surname>Grant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">10699</biblScope>
		</imprint>
	</monogr>
	<note>Space Telescopes and Instrumentation</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Nuclear instruments and methods in physics research section A: Accelerators, Spectrometers, Detectors and Associated Equipment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Agostinelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sea</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">506</biblScope>
			<biblScope unit="page" from="250" to="303" />
		</imprint>
	</monogr>
	<note>GEANT4-a simulation toolkit</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ATHENA end-to-end simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jrn</forename><surname>Wilms</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Space Telescopes and Instrumentation 2014: Ultraviolet to Gamma Ray</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">9144</biblScope>
		</imprint>
	</monogr>
	<note>International Society for Optics and Photonics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kdd</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">34</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scikit-Learn ;</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning in Python, Pedregosa</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural networks and physical systems with emergent collective computational abilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences 79</title>
		<meeting>the national academy of sciences 79</meeting>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="2554" to="2558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Tensorflow: a system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martn</forename><surname>Abadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OSDI</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
