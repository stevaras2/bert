<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/lopez/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5-SNAPSHOT" ident="GROBID" when="2019-03-19T09:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Demystifying the workings of Lending Club</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhatnagar</forename><surname>Pujun</surname></persName>
							<email>pujun@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Chow Nick</orgName>
								<address>
									<addrLine>353 Serra Mall Stanford, 353 Serra Mall Stanford, 353 Serra Mall Stanford</addrLine>
									<postCode>94305, 94305, 94305</postCode>
									<region>CA, CA, CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lai</forename><surname>Max</surname></persName>
							<email>maxlai@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Chow Nick</orgName>
								<address>
									<addrLine>353 Serra Mall Stanford, 353 Serra Mall Stanford, 353 Serra Mall Stanford</addrLine>
									<postCode>94305, 94305, 94305</postCode>
									<region>CA, CA, CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Demystifying the workings of Lending Club</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Lending Club is the world's largest peer-topeer marketplace connecting borrowers and investors. They claim to transform the banking system by operating at a lower cost than a traditional bank and thereby making credit more affordable and investing more rewarding. Over the last 8 years, the number of loans in the marketplace has increased exponentially, yet little is known about the algorithms that determine if a loan is approved, and if it is, the interest rate a loan is offered at. In this paper we attempt to demystify the inner workings of this marketplace by applying machine learning techniques to Lending Club's publicly available dataset.</p><p>Using a basket of supervised learning techniques, we find that we can build highly accurate models, with an F-measure of up to 98%, that predict if an application will be approved. We also find that if a loan is approved, we can determine the interest rate at which the loan will be offered at. We provide an analysis of the performance of different machine learning models applied to our dataset.</p><p>With the models generated, we discover that Lending Club has gradually relaxed its application loan approval criteria. We hypothesize that this was due to the company preparing for its initial public offering, which eventually happened in 2014. In addition, we find that certain features, such as if the loan is a credit card refinancing loan, are constantly predictive of whether a loan is approved or denied. Using this newly discovered insight, we suggest some ways to game Lending Club's system to increase an applicant's chances of approval.</p><p>Finally, using effective clustering and visualization techniques, we uncover and exhibit structure in this rich dataset, which can be exploited to artificially generate more examples, specially for the years which only a limited number of training examples are available.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Lending Club, as an online banking platform, is becoming increasingly popular ever since it started in 2007. By applying machine learning techniques, we intend to investigate following questions:</p><p>• Using supervised methods, can one predict if a loan application would be approved?</p><p>• Given that an application is approved, can we correctly predict the offered interest rate?</p><p>• Has the standard of Lending Club approvals changed over the years of 2007-2015, especially after their initial public offering?</p><p>• Can we extract a trend of how the significance of various features has changed over the years? Can this information be used to game their online system to increase applications' chance of approval?</p><p>• Can we find some structure among this rich dataset which can be used to generate artificial data for our models, especially for the earlier years of Lending Club?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Pre-Processing</head><p>The dataset, available at Lending Club Website, is a comprehensive dataset of all applications for peer-topeer loans on the Lending Club platform between 2007 and 2015. The data files are csv files which are split by whether the loan is approved or denied. The following is a plot of the Lending Club application statistics each year: Note that the number of training examples grows exponentially over the years as Lending Club has expanded rapidly. The amount of loan applications grew from 5,000 in 2007 to over 3 million in 2015.</p><p>Denied applications contain far fewer features than approved applications. For the approval classification problem, we maximize the available data by combining the features available in both the approved and denied applications. For the interest rate regression problem, we do not have to analyze the denied applications and hence we can use all the features available in the approved applications. Hence, we decide to separate pre-processing for classification and regression. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Classification Task: Loan Approval</head><p>To determine if the criteria for approval has changed over the years, we first split up the datasets according to the year the loan was issued. We use R and Python to pre-process the data. All pre-processing scripts used can be found on our Github repository.</p><p>Before we start our analysis, we extract the common subset of features from the approved and denied files and combine the two datasets together for each year.</p><p>We also notice that in the approved dataset there are only 14 unique values for the Purpose of loan column, while in some years of the denied dataset there are over 10,000 unique values. However, we observe that the top 100 unique values for each year in the denied dataset represents over 99% of that year's denied loan applications (with the 2007 data as an exception). Therefore, in hope of cleaning the data, for each year we create a function that maps the top 100 unique values into the 14 unique values in the approved dataset. We delete the last 1% of denied loan applications. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Regression Task: Interest Rate</head><p>Using our general intuition, we carefully select 22 out of 111 features from the approved data, where about half of the features are empty. Loan amount, Interest rate and Loan quality are among some of the selected features. We continue processing the data as highlighted in the previous sub-section for each year.</p><p>We notice that many of the features, such as Income, have a right skew. Therefore we log-normalize the data with mean 0 and variance 1 to ensure our algorithm treats each feature equally. We run linear regression on this data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Classification Task</head><p>In order to find the model that works best, we apply several machine learning algorithms onto our dataset and compare their performances. For each year of data, we independently run Support Vector Machines <ref type="bibr" target="#b1">[2]</ref>, Logistic Regression, Boosting <ref type="bibr" target="#b4">[5]</ref>, Random Forest <ref type="bibr" target="#b0">[1]</ref> and Artificial Neural Network <ref type="bibr" target="#b7">[8]</ref>, for a total of 45 iterations. For fast training, we use Java, Python, and Weka <ref type="bibr" target="#b2">[3]</ref>, scikitlearn <ref type="bibr" target="#b6">[7]</ref>. We split the data into 70% training set and 30% testing set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Regression Task</head><p>After successfully training a classifier that can predict if a loan will be approved, next step is to predict the interest rate for the approved loans. For accomplishing this task, we apply regression techniques after normalizing data. In order to measure the accuracy of our model, we decide to measure performance by using root mean squared (RMS) error because we want to heavily penalize the model for incorrectly predicting the interest rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Clustering Task</head><p>Hoping to find latent structure within the data, we use unsupervised techniques to cluster the data. To investigate this, we remove the State and Purpose of loan features and cluster the normalized data using K-means <ref type="bibr" target="#b3">[4]</ref>. In order to visualize this data, we implement t-SNE <ref type="bibr" target="#b5">[6]</ref> using Python. t-Distributed Stochastic Neighbor Embedding (t-SNE) is a (prize-winning) technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. We use this approach to find if our resulting clusters indicate some latent trend within the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Classification Results</head><p>For each year of our data, we calculate the F-measure associated with the dataset using the confusion matrices. We use this as our primary measure of performance for each of the models because we notice that evaluating model performance based on classification error is potentially misleading. As only a small fraction of the applications (5-15%) are successful in any year, classifiers, such as ADA-Boost for the 2009 data, can get a low classification error just by classifying every loan as denied. Therefore, we use the F-measure, which is a combination of precision and recall, to evaluate our models' performance. As we run the models on datasets with more examples, we expect the accuracy to trend upwards. We believe the models' accuracy for 2007 in <ref type="figure" target="#fig_3">Figure 4</ref> is higher than expected because of a variety of reasons. First, since this was the first year that Lending Club open-sourced their data, their data isn't consistent. During the pre-processing stage, we end up dropping most of the examples, which we suspect ultimately leads to over-simplification and enables us to learn a simpler model that works quite well with the remaining 2007 data. We also hypothesize that in 2007, Lending Club was using a simpler algorithm with limited features, which is easily estimated by our classifiers.  <ref type="figure" target="#fig_4">Figure 5</ref> shows confusion matrices for the classification results. During the analysis, we see that different algorithms classify examples differently and therefore we decide to look at the confusion matrices. In some cases, like ADABoost, the model classifies all examples are positive and doesn't do anything intelligent. We identify these models and make sure to not use this for future testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Has Loan Quality Changed?</head><p>We see convincing evidence that Lending Club has gradually relaxed its loan approval standards. <ref type="figure">Figure 6</ref> shows a plot of Debt-to-Income (DTI) for all approved loans in each year between 2007-2015. The graph shows that Lending Club increased the maximum DTI that it will accept on applications gradually from 25% in 2007 to 40% in 2015. Lending Club also relaxed the maximum Loan Amount that it will accept from $25,000 in 2007 to $35,000 in 2015, as seen in <ref type="figure">Figure 7</ref>.</p><p>A possible explanation for a relaxation over the years is that the management team wanted to generate greater revenue growth and higher profits to prepare for an eventual initial public offering (which happened in 2014). Since a relaxation would result in the approval of more loans, and since Lending Club charges a percentage fee on every loan that is funded on its platform, increasing the maximum Loan Amount and DTI would result in higher profits and higher valuation of the company. We notice that there are certain features that are constantly predictive of whether a loan is approved or denied. In <ref type="figure" target="#fig_6">Figure 8</ref>, we plot some of the features that are most indicative of approval and denial. This plot shows the ranking of the resulting coefficients of the Logistic Regression. The higher the value, the more predictive the feature is of approval for that year, while the lower the value, the more predictive the feature is of denial for the year.</p><p>We notice that educational loans are likely to be denied, whilst credit card consolidation loans are likely to be approved. This can be explained through economic intuition. Education loans are likely to be denied because seekers of these loans, students, are unlikely to have a stable source of income and hence are likely to have a higher chance of defaulting. On the other hand, credit card refinancing applications are likely to be approved because people who want to refinance credit card debt must already have a credit card, which itself requires a stringent credit approval process.</p><p>Renewable energy loans tell a particularly interesting story. In 2008 and 2009, renewable energy loans were highly predictive of loan approval. However, this predictiveness disappeared soon after and by 2013 renewable energy loans were actually predictive of loan denial. An explanation for this effect is that in 2008 the Energy Improvement and Extension Act was passed, which provided tax credits to renewable energy initiatives. Therefore the borrowers had, in effect, higher disposable income and hence a higher probability of paying back the loan compared to before. By 2014, many of these tax credits had been phased out, and therefore Lending Club has reversed their algorithm to account for this change.</p><p>An immediate takeaway from this analysis is that applicants should state that the purpose of the loan is for credit card consolidation to maximize their chances of approval. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Regression Results</head><p>We use regression to predict the interest rate for approved applications. After running linear regression, we find that the RMS errors are very low (less than 0.003 in 2015) because Loan Grade is included as a feature. As Loan Grade is determined by an algorithm within Lending Club, we decide to not use it and implement different data processing techniques on the remaining data.</p><p>We perform PCA and run regression on the transformed data. We hope that by reducing the number of dimensions, we would be able to counter noise present in the data and account for less data, especially for the earlier years, and consequently decrease the generalization error of our interest rate predictions. To determine the number of principle components to include, we run PCA on the normalized data for each year. The results are shown in figure 9. We notice that there is a noticeable 'kink' in the data after 3 principal components, which indicates that most of the variance is captured by the first three eigenvectors. Hence we decide to use k = 3 for PCA.  <ref type="figure" target="#fig_0">Figure 10</ref> shows the RMS error of our interest rate predictions using different data processing techniques.</p><p>Analyzing the results, we note the following insights: • Loan Grade feature is a near perfect predictor of the interest rate: This is not surprising, as Lending Club states that they determine the interest rate based on the Loan Grade calculated for that loan. We notice that we generally do not have perfect predictions on interest rates for different Loan Grade. This is likely because loan rates for different Loan Grade will change over time (but the low RMS error shows that interest rates for a specified Loan Grade do not vary drastically over a year).</p><p>• Increased complexity of Lending Club's system over the years: Even though there are more data samples each passing year, our RMS error has steadily increased. In 2007, our simple linear regression algorithm did a good job of predicting the interest rate of a loan, with a RMS error of 0.02. Using the same type of model, our 2015 RMS error is over 0.03. It also seems that their model now uses more features, some of which may not publicly available.</p><p>• Low dimensionality of the approved data: Taking the first 3 (of over 30) principal components generates decent predictions. We realize a RMS error that is about 25% greater than that of taking all principal components. This shows most of the important determinants of interest rate can be represented by the first three principal components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Clustering Results</head><p>While trying to build models to predict the interest rate and if a loan will be approved, we notice some structure in the data and hypothesize that we may be able to find clusters that are highly indicative of interesting trends. We decide to apply techniques from our unsupervised toolbox to find structures but quickly discover that there isn't any intuitive way of visualizing the results of our experiments. After doing some research, we find t-SNE as one of the ways to visualize our results. We discover the following interesting trends: As seen in <ref type="figure" target="#fig_0">figure 11</ref>, we generate clear clusters when we remove the purpose attribute and try clustering the examples. We observe that the results are sparse and are localized to different parts in the high dimensional space. This proves that our hypothesis about some inherent structure in the data. Also, using the found clusters, we can potentially generate even more examples, which can in turn be used to improve our models performance, especially for the starting years where we have limited data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Number of applications received by Lending Club per year</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Classification Task: Processed Lending Club Data for 2015</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Regression</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>F-measure values by algorithm and yearFigure 4is a visualization of how the machine learn- ing models compare to each other over the years. Over- all, we find the Random Forest algorithm generally produces the best predictions, with a F-measure of 98% in 2015, but Artificial Neural Network performs equally well as the number of training examples in- creases over the years.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Confusion matrices for year 2009</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 : 2015 Figure 7 :</head><label>620157</label><figDesc>Debt-To-Income of Approved Applications 2007-2015Figure 7: Loan</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Most significant features by year</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Degree of variance captured by PCA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Regression results for Interest Rate.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgments</head><p>We would like to thank Dr. Duchi and all 229 TAs for guiding us and consistently assisting us throughout the project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Random Forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
		<idno type="doi">10.1023/A:1010933404324</idno>
		<idno>ISSN: 0885- 6125. DOI: 10 . 1023 / A : 1010933404324. URL</idno>
		<ptr target="http://dx.doi.org/10.1023/A:1010933404324" />
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Tutorial on Support Vector Machines for Pattern Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burges</surname></persName>
		</author>
		<idno type="doi">10.1023/A:1009715923555</idno>
		<idno>1384-5810. DOI: 10.1023/ A : 1009715923555. URL</idno>
		<ptr target="http://dx.doi.org/10.1023/A:1009715923555" />
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="167" />
			<date type="published" when="1998-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The WEKA Data Mining Software: An Update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<idno type="doi">10.1145/1656274.1656278</idno>
		<idno>1931-0145. DOI: 10 . 1145 / 1656274 . 1656278</idno>
		<ptr target="http://doi.acm.org/10.1145/1656274.1656278" />
	</analytic>
	<monogr>
		<title level="j">In: SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An Efficient k-Means Clustering Algorithm: Analysis and Implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapas</forename><surname>Kanungo</surname></persName>
		</author>
		<idno type="doi">10.1109/TPAMI.2002.1017616</idno>
		<idno>ISSN: 0162-8828. DOI: 10 . 1109 / TPAMI . 2002 . 1017616</idno>
		<ptr target="http://dx.doi.org/10.1109/TPAMI.2002.1017616" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="881" to="892" />
			<date type="published" when="2002-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">AdaBoost with SVM-based Component Classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Sung</surname></persName>
		</author>
		<idno type="doi">10.1016/j.engappai.2007.07.001</idno>
		<idno>DOI: 10.1016/ j.engappai.2007.07.001</idno>
		<ptr target="http://dx.doi.org/10.1016/j.engappai.2007.07.001" />
	</analytic>
	<monogr>
		<title level="j">Eng. Appl. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="952" to="1976" />
			<date type="published" when="2008-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Journal of Machine Learning Research 9</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">85</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Multisensor ANN Fusion Method for Accurate Displacement Measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Postolache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Buletinul Institutului Politehnic din Iasi XLV(IL).Fasc 5A</title>
		<imprint>
			<date type="published" when="1999-11" />
			<biblScope unit="page" from="363" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Figure 11: t-SNE visualization of found clusters</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
